# AVATAR OnE 플랫폼 기능 명세서

Builder → 테스트 실행 → 워크로드 실행 요청 → 승인 → 스케줄링 → 결과 조회
전체 워크플로우 기반 기능 명세

| 항목 | 내용 |
|------|------|
| 버전 | 1.3 |
| 작성일 | 2025-02-02 |
| 수정일 | 2026-02-09 |
| 대상 | 고객 전달용 |

---

## 1. 전체 워크플로우

본 플랫폼의 핵심 워크플로우를 다음과 같이 정의한다. 각 단계별 상세 기능은 이후 섹션에서 기술한다.

| 단계 | 이름 | 설명 |
|------|------|------|
| 1 | Builder로 파이프라인 정의 | 사용자가 독립 컨테이너로 실행되는 컴포넌트를 정의하고(컴포넌트별 이미지, 자원 할당), 컴포넌트 간 실행 의존 관계를 워크플로우로 구성하면 스펙 파일(JSON)이 생성된다. |
| 2 | 워크로드 실행 요청 | 생성된 파이프라인 스펙을 조회하고, 필요 자원량과 함께 워크로드 실행을 요청한다. 테스트 실행 결과(run)를 참조할 수 있다. |
| 3 | 테스트 실행 및 승인 | 사용자가 파이프라인을 테스트 실행하여 정상 동작을 검증한다. 개별 컴포넌트의 자원 요청량이 임계치 이상이면 관리자 승인 후 실행한다. |
| 4 | 실행 대기열 및 우선순위 관리 | 승인된 워크로드가 실행 대기열에 진입한다. 관리자가 대기 중인 작업의 우선순위를 조정할 수 있다. |
| 5 | 워크로드 실행 및 리소스 모니터링 | 스케줄러가 자원을 할당하여 워크로드를 실행한다. 관리자는 실시간 리소스 현황을 확인한다. |
| 6 | 결과 모델 저장 및 조회 | 워크로드 종료 시 결과 모델이 자동 저장되고, 목록을 통해 조회할 수 있다. |

---

## 2. Builder (파이프라인 정의)

### 핵심 개념

Builder의 결과물은 "스펙 파일"이다. 이 스펙 파일은 컴포넌트별 스펙을 정의한 파이프라인이며,
동시에 스펙(Spec) = 코드(Code) = JSON = Class 역할을 한다. 각 컴포넌트는 독립된 컨테이너로 실행되며, 고유한 이미지와 자원 할당을 가진다.

Builder는 두 개의 탭으로 구성된다:
- **컴포넌트 관리**: 컴포넌트를 추가, 편집, 삭제하고 각각의 이미지와 자원을 할당한다.
- **워크플로우 구성**: 컴포넌트 간 실행 순서와 의존 관계를 정의하고 시각적으로 확인한다.

### 2.1 기능 명세

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| BL-01 | 컨테이너 이미지 입력 | 각 컴포넌트별로 학습에 사용할 컨테이너 이미지 정보를 입력한다 (레지스트리 주소, 태그). 각 컴포넌트는 독립 컨테이너로 실행된다 | P0 | Phase 1 |
| BL-02 | 환경 변수 설정 | 컨테이너 실행 시 필요한 환경 변수를 Key-Value 형식으로 입력한다. 환경 변수는 파이프라인 레벨로 모든 컴포넌트가 공유한다 | P0 | Phase 1 |
| BL-03 | 컴포넌트 스펙 정의 | 파이프라인을 구성하는 각 컴포넌트의 스펙을 정의한다 (컨테이너 이미지, GPU 유형/수, 메모리, 컴포넌트 유형, 파라미터, 실행 순서) | P0 | Phase 1 |
| BL-04 | 스펙 파일 생성 | 입력된 구성을 기반으로 스펙 파일(JSON)을 자동 생성한다. 이 파일이 곧 워크로드 실행의 기준이 된다 | P0 | Phase 1 |
| BL-05 | 스펙 파일 조회 | 생성된 스펙 파일 목록을 조회하고 상세 내용을 확인한다 | P0 | Phase 1 |
| BL-06 | 컴포넌트별 자원 할당 | 각 컴포넌트에 GPU 유형, GPU 수, 메모리를 독립적으로 할당한다. 컴포넌트별 임계치 초과 여부를 실시간 표시한다 | P0 | Phase 1 |
| BL-07 | 워크플로우 구성 | 워크플로우 구성 탭에서 컴포넌트 간 실행 의존 관계(엣지)를 정의하고, 실행 순서를 조정할 수 있다 | P0 | Phase 1 |
| BL-08 | 워크플로우 시각화 | 정의된 워크플로우를 SVG 다이어그램으로 실시간 미리보기한다. 컴포넌트 유형별 색상 구분, 방향 화살표 표시 | P0 | Phase 1 |
| BL-09 | 워크플로우 유효성 검증 | 순환 참조(cycle) 감지, 자기 참조(self-loop) 방지, 중복 연결 방지. 유효성 위반 시 오류 메시지 표시 | P0 | Phase 1 |

### 2.2 스펙 파일 구조 (예시)

스펙 파일은 다음과 같은 구조로 구성된다. 이 파일이 곧 워크로드 실행의 기준이 된다:

| 필드 | 설명 |
|------|------|
| pipeline_id | 파이프라인 고유 식별자 |
| version | 스펙 파일 버전 |
| env_vars | 환경 변수 목록 (Key-Value). 파이프라인 레벨로 모든 컴포넌트가 공유 |
| components[] | 컴포넌트 목록: 각 컴포넌트의 이미지, 자원, 유형, 파라미터, 실행 순서 (아래 상세) |
| workflow[] | 컴포넌트 간 실행 의존 관계 (from → to 엣지 목록) |
| storage | 저장소 설정 |
| created_at | 생성 일시 |
| test_run_ref | 테스트 실행 결과 참조 (run ID, 선택 사항) |

#### components[] 항목 구조

| 필드 | 설명 |
|------|------|
| order | 실행 순서 |
| name | 컴포넌트 이름 |
| type | 컴포넌트 유형 (trainer, data_loader, preprocessor, evaluator) |
| image | 컨테이너 이미지 정보 (registry, tag) |
| resources | 필요 자원량 (gpu_type, gpu_count, memory) |
| params | 컴포넌트 파라미터 |

#### 스펙 파일 예시

```json
{
  "pipeline_id": "PL-A1B2C3",
  "name": "LLM-FineTune-v3",
  "version": "1.0.0",
  "env_vars": {
    "NCCL_DEBUG": "INFO",
    "CUDA_VISIBLE_DEVICES": "all"
  },
  "components": [
    {
      "order": 1,
      "name": "data-loader",
      "type": "data_loader",
      "image": { "registry": "registry.avatar.io/data-loader", "tag": "1.0" },
      "resources": { "gpu_type": "V100", "gpu_count": 1, "memory": "32GB" },
      "params": {}
    },
    {
      "order": 2,
      "name": "preprocessor",
      "type": "preprocessor",
      "image": { "registry": "registry.avatar.io/preprocessor", "tag": "2.1" },
      "resources": { "gpu_type": "A100", "gpu_count": 2, "memory": "64GB" },
      "params": { "batch_size": 128 }
    },
    {
      "order": 3,
      "name": "trainer",
      "type": "trainer",
      "image": { "registry": "registry.avatar.io/llm-trainer", "tag": "3.1" },
      "resources": { "gpu_type": "A100", "gpu_count": 4, "memory": "128GB" },
      "params": { "lr": 0.001, "epochs": 30 }
    },
    {
      "order": 4,
      "name": "evaluator",
      "type": "evaluator",
      "image": { "registry": "registry.avatar.io/evaluator", "tag": "1.5" },
      "resources": { "gpu_type": "V100", "gpu_count": 1, "memory": "16GB" },
      "params": {}
    }
  ],
  "workflow": [
    { "from": "data-loader", "to": "preprocessor" },
    { "from": "preprocessor", "to": "trainer" },
    { "from": "trainer", "to": "evaluator" }
  ],
  "storage": {
    "type": "distributed",
    "path": "/training-data/llm-finetune-v3"
  },
  "created_at": "2026-02-09T09:00:00.000Z"
}
```

---

## 3. 워크로드 실행 요청 및 승인

### 3.1 실행 요청 (사용자)

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| WR-01 | 스펙 파일 선택 | Builder에서 생성된 스펙 파일 목록을 조회하고, 실행할 파이프라인을 선택한다 | P0 | Phase 1 |
| WR-02 | 자원 요청량 설정 | 워크로드 실행에 필요한 GPU 수/유형, 메모리, CPU, 최대 실행 시간을 설정한다. 스펙 파일 선택 시 컴포넌트별 최대 자원값으로 자동 입력되며, 사용자가 수정할 수 있다 | P0 | Phase 1 |
| WR-03 | 테스트 run 참조 | 테스트 실행 결과(run)를 본 실행 요청에 annotate하여 참조한다. 사전 테스트 실행은 선택 사항이다 | P0 | Phase 1 |
| WR-04 | 실행 요청 제출 | 스펙 파일 + 자원 요청 + 테스트 run 참조를 묶어 파이프라인 실행을 요청한다 | P0 | Phase 1 |
| WR-05 | Operator 업로드 | 워크로드 실행 요청 시점에 Operator를 함께 업로드한다 | P1 | Phase 2 |

### 3.2 테스트 실행 및 승인 (사용자/관리자)

#### 테스트 및 승인 프로세스 개요

사용자는 파이프라인을 테스트 실행하여 정상 동작을 검증할 수 있다. 본 실행 요청 시 기존 테스트 실행 결과(run)를 참조(annotate)할 수 있다. 개별 컴포넌트의 자원 요청량이 설정된 임계치 이상인 경우 관리자 승인 후 실행되며, 임계치 미만이면 즉시 실행된다.

**자원 임계치 승인 기준:** 파이프라인을 구성하는 개별 컴포넌트 중, 어느 하나라도 GPU ≥ 4기 또는 메모리 ≥ 128GB이면 관리자 승인이 필요하다.

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| AP-01 | 실행 요청 목록 조회 | 제출된 파이프라인 실행 요청 목록을 조회한다 (상태: 대기/승인대기/승인/반려) | P0 | Phase 1 |
| AP-02 | 요청 상세 검토 | 스펙 파일 내용, 요청 자원량, 신청자 정보를 상세히 확인한다 | P0 | Phase 1 |
| AP-03 | 테스트 실행 | 사용자가 파이프라인을 테스트 실행하여 정상 동작을 검증한다. 테스트 실행은 일반 파이프라인 실행과 동일하게 동작한다 | P0 | Phase 1 |
| AP-04 | 테스트 결과 확인 | 테스트 실행의 실행 로그, 성공/실패 여부, 결과 요약을 확인한다. 본 실행 요청 시 해당 테스트 run을 annotate하여 참조할 수 있다 | P0 | Phase 1 |
| AP-05 | 승인/반려 처리 | 개별 컴포넌트의 자원 요청량이 임계치 이상이면 관리자 승인 후 실행 대기열에 진입. 임계치 미만이면 즉시 실행. 반려 시 사유를 코멘트로 기록한다 | P0 | Phase 1 |

---

## 4. 실행 대기열 및 우선순위 관리

### 운영 범위

현재 실행 중인 파이프라인을 강제 종료할 필요는 없다. 관리자는 대기 중인 파이프라인 대기열에서 우선순위를 조정하여 실행 순서를 결정한다. 우선순위는 파이프라인 레벨로 관리한다.

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| QU-01 | 대기열 목록 조회 | 실행 대기 중인 워크로드 목록을 현재 우선순위 순서로 조회한다 | P0 | Phase 1 |
| QU-02 | 우선순위 표시 | 각 대기 워크로드의 현재 우선순위, 요청 자원량, 신청자, 신청일시를 표시한다 | P0 | Phase 1 |
| QU-03 | 우선순위 조정 | 관리자가 대기 중인 워크로드의 우선순위를 변경하여 실행 순서를 조정한다 | P0 | Phase 1 |
| QU-04 | 워크로드 상태 표시 | 각 워크로드의 상태를 표시한다 (대기, 실행 중, 완료, 실패, 취소) | P0 | Phase 1 |
| QU-05 | 요청 자원량 표시 | 각 대기 워크로드가 요청한 GPU 수/유형, 메모리, CPU 정보를 함께 표시한다 | P0 | Phase 1 |

### 4.1 대기열 조회 화면 구성 (예시)

| 순서 | 워크로드명 | 우선순위 | 요청 자원 | 신청자 | 상태 | 신청일시 |
|------|-----------|----------|-----------|--------|------|----------|
| 1 | LLM-FineTune-v3 | 높음 | A100 x 4, 128GB | 김연구원 | 대기 | 2025-02-01 |
| 2 | ResNet-Exp-42 | 보통 | V100 x 2, 64GB | 박연구원 | 대기 | 2025-02-01 |
| 3 | DataPrep-Batch | 낮음 | CPU x 8, 32GB | 이연구원 | 대기 | 2025-02-02 |

---

## 5. 리소스 관리

### 5.1 리소스 현황 조회

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| RS-01 | 전체 리소스 현황 | 클러스터 전체 리소스의 요청량 / 사용량 / 유휴량을 조회한다 | P0 | Phase 1 |
| RS-02 | GPU 현황 | GPU별 상태를 조회한다: 총 수량, 할당된 수량(요청량), 실제 사용량, 유휴 수량 | P0 | Phase 1 |
| RS-03 | 메모리 현황 | 전체 메모리의 요청량 / 사용량 / 유휴량을 조회한다 | P0 | Phase 1 |
| RS-04 | 노드 상태 | 각 노드의 상태(Active/Drain/Down)와 자원 현황을 확인한다 | P0 | Phase 1 |
| RS-05 | 워크로드별 자원 사용량 | 현재 실행 중인 워크로드별 실제 자원 사용량을 확인한다 | P0 | Phase 1 |
| RS-06 | 사용량 추이 차트 | 시간대별 리소스 사용량 추이를 차트로 표시한다 | P1 | Phase 2 |

### 5.2 리소스 현황 화면 구성 (예시)

| 리소스 | 총 수량 | 요청량 (할당) | 실제 사용량 | 유휴량 |
|--------|---------|---------------|-------------|--------|
| GPU (A100) | 16기 | 12기 | 10기 (62.5%) | 4기 |
| GPU (V100) | 8기 | 6기 | 6기 (75.0%) | 2기 |
| 메모리 | 2,048 GB | 1,536 GB | 1,200 GB (58.6%) | 512 GB |
| CPU | 256 코어 | 180 코어 | 140 코어 (54.7%) | 76 코어 |

---

## 6. 결과 모델 관리

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| MD-01 | 결과 모델 자동 저장 | 워크로드 종료 시 학습된 모델 아티팩트를 자동으로 모델 저장소에 저장한다 | P0 | Phase 1 |
| MD-02 | 모델 목록 조회 | 저장된 모델 목록을 조회한다 (모델명, 워크로드 참조, 생성일시, 크기) | P0 | Phase 1 |
| MD-03 | 모델 상세 조회 | 모델의 상세 정보를 확인한다: 원본 스펙 파일, 학습 구성, 실행 로그, 생성 메타데이터 | P0 | Phase 1 |
| MD-04 | 모델 다운로드 | 저장된 모델 아티팩트를 다운로드한다 | P0 | Phase 1 |
| MD-05 | 모델 버전 관리 | 동일 파이프라인에서 생성된 모델들의 버전 이력을 관리한다 | P1 | Phase 2 |
| MD-06 | 모델 비교 | 여러 모델의 성능 메트릭을 나란히 비교한다 | P1 | Phase 2 |

### 6.1 모델 목록 화면 구성 (예시)

| 모델명 | 원본 워크로드 | 생성일시 | 크기 | 상태 | 작업 |
|--------|-------------|----------|------|------|------|
| llm-ft-v3-final | LLM-FineTune-v3 | 2025-02-02 | 14.2 GB | 완료 | 조회 \| 다운로드 |
| resnet-exp42-ep50 | ResNet-Exp-42 | 2025-02-01 | 380 MB | 완료 | 조회 \| 다운로드 |

---

## 7. 워크로드 스케줄링 (HPC)

승인된 워크로드를 실제 HPC 인프라에서 실행하는 계층이다. 대기열의 우선순위와 자원 가용성에 따라 자동으로 자원을 할당하고 실행한다.

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| SC-01 | 우선순위 기반 실행 | 대기열의 우선순위 순서대로 자원이 확보되면 자동 실행한다 | P0 | Phase 1 |
| SC-02 | GPU 할당 | 요청된 수량과 유형의 GPU를 워크로드에 할당한다 | P0 | Phase 1 |
| SC-03 | 작업 상태 추적 | 워크로드 수명주기 추적: 대기 → 실행 중 → 완료/실패 | P0 | Phase 1 |
| SC-04 | 모델 자동 저장 트리거 | 워크로드 정상 종료 시 결과 모델을 자동으로 모델 저장소에 저장한다 | P0 | Phase 1 |
| SC-05 | 로그 수집 | 실행 중 및 종료 후 워크로드 로그를 수집하여 조회 가능하게 한다 | P0 | Phase 1 |
| SC-06 | GPU 파티셔닝 | HAMi를 활용한 단일 GPU 메모리/코어 수준 분할 (개발/추론 용도) | P1 | Phase 2 |

---

## 8. 저장소

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| ST-01 | 스펙 파일 저장소 | Builder가 생성한 스펙 파일(JSON)을 저장한다 | P0 | Phase 1 |
| ST-02 | 모델 저장소 | 워크로드 결과 모델 아티팩트를 저장하고 관리한다 | P0 | Phase 1 |
| ST-03 | 테스트 실행 저장소 | 테스트 실행 결과 및 참조 데이터를 저장한다 | P0 | Phase 1 |
| ST-04 | 실행 로그 저장소 | 워크로드 실행 로그를 수집하고 저장한다 | P0 | Phase 1 |
| ST-05 | 분석 결과 저장소 | Operator 분석 결과를 저장하고 관리한다 | P1 | Phase 2 |

---

## 9. 권한 관리 및 인증

| ID | 기능명 | 설명 | 우선순위 | 구현 단계 |
|----|--------|------|----------|-----------|
| AU-01 | 역할 기반 접근 제어 | 관리자 / 연구원 / 뷰어 역할별 권한을 부여한다 | P0 | Phase 1 |
| AU-02 | 사용자 계정 관리 | 사용자 계정의 생성, 수정, 비활성화를 관리한다 | P0 | Phase 1 |
| AU-03 | API 인증 | 토큰 기반 API 인증 및 SSO 연동 (OIDC/SAML) | P1 | Phase 2 |
| AU-04 | 감사 로깅 | 모든 사용자 행위에 대한 감사 추적 기록 | P1 | Phase 2 |

---

## 10. 권장 기술 스택

| 계층 | 기술 | 선정 근거 |
|------|------|-----------|
| 컨테이너 오케스트레이션 | Kubernetes | HPC/ML 워크로드 관리의 사실상 표준 |
| 작업 스케줄링 | Airflow + K8s | Airflow로 파이프라인 우선순위 관리, KubernetesPodOperator로 태스크 실행 |
| GPU 파티셔닝 | HAMi | 오픈소스 GPU 메모리/코어 분할 (개발/추론 용도) |
| 모니터링 | Prometheus + Grafana + DCGM | 메트릭 수집 및 GPU 모니터링 업계 표준 |
| 저장소 (모델) | S3 호환 객체 스토리지 | 확장 가능한 모델/결과물 아티팩트 저장 |
| 저장소 (학습 데이터) | Ceph | 통합 분산 스토리지 (블록/객체/파일 통합 지원) |
| 플랫폼 백엔드 | FastAPI (Python) | Python ML 생태계 통합, 비동기 API 서버 |
| 플랫폼 프론트엔드 | React + TypeScript | 인터랙티브 관리 화면 및 사용자 UI |
| 데이터베이스 | PostgreSQL | 구성/메타데이터/감사 로그 저장 |
| 인증 | Keycloak | OIDC/SAML 지원 엔터프라이즈 SSO |

---

## 11. 구현 로드맵

### Phase 1: 핵심 워크플로우 (0~2개월)

전체 워크플로우의 기본 형상을 완성한다. Builder로 파이프라인을 정의하고, 테스트 실행, 실행 요청, 관리자 승인, 대기열 관리, 실행, 결과 모델 조회까지 전체 흐름이 동작한다.

- Builder: 컴포넌트별 컨테이너 이미지 + 자원 할당 + 환경 변수 + 워크플로우 구성 → 스펙 파일(JSON) 생성
- 워크플로우: 컴포넌트 간 의존 관계 정의, 실행 순서 편집, SVG 다이어그램 미리보기, 유효성 검증
- 실행 요청: 스펙 파일 선택 + 자원 요청(자동 입력) + 테스트 run 참조
- 승인: 요청 검토 → 테스트 run 참조 확인 → 컴포넌트별 자원 임계치 확인 → 승인/반려/즉시실행
- 대기열: 우선순위 조회/조정, 요청 자원량 표시
- 스케줄링: 우선순위 기반 자동 실행, GPU 할당
- 리소스: 요청량/사용량/유휴량 현황 조회
- 결과: 모델 자동 저장, 목록 조회, 상세 확인, 다운로드

### Phase 2: 고도화 (2~4개월)

Builder 고도화, 고급 스케줄링, Operator 통합 등을 추가한다. Phase 1 기반 피드백을 반영한다.

- Builder 고도화: 컴포넌트 템플릿 라이브러리, 스펙 파일 버전 관리, 드래그 앤 드롭 기반 시각적 워크플로우 편집기
- Operator 통합: 워크로드 요청 시 Operator 업로드, 분석 결과 저장/조회
- 고급 스케줄링: GPU 파티셔닝 (HAMi)
- 모델 관리: 버전 관리, 모델 비교 등
- 감사: 사용자 행위 감사 로깅
